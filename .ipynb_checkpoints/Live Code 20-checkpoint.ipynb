{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150, 4), (150,))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset loader\n",
    "from sklearn import datasets\n",
    "\n",
    "# model training and evalutation utilities \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold # this is one way to generate folds\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# models\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import linear_model\n",
    "\n",
    "# toy data\n",
    "X, y = datasets.load_iris(return_X_y=True)\n",
    "X.shape, y.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What you should learn/be aware of based on this lecture\n",
    "Key sklearn functions:\n",
    "\n",
    "train_test_split\n",
    "cross_validate\n",
    "Fold generators: KFold and StratifiedKFold\n",
    "Scoring functions per last lecture and how to pass to cross_validate\n",
    "How to compare different models by looping over them with cross_validate, GridSearchCV, or RandomizedSearchCV\n",
    "Not covered today but you should check out:\n",
    "\n",
    "confusion_matrix and classification_report (helpful to evaluate models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A simple \"split, train, evaluate\" example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9066666666666666"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split the data with 50% in each set\n",
    "X1, X2, y1, y2 = train_test_split(X, y, random_state=0,\n",
    "                                  train_size=0.5)\n",
    "\n",
    "# fit the model on one set of data\n",
    "# ignore the model I choose here, its not important what\n",
    "model = KNeighborsClassifier(n_neighbors=1)\n",
    "model.fit(X1, y1) # fit on the \"training data\" X1 and  y1\n",
    "\n",
    "# evaluate the model on the second set of data\n",
    "y2_model = model.predict(X2) # using X2 (out-of-sample data), predict y2\n",
    "accuracy_score(y2, y2_model) # see how close y2 is to prediction (fraction of all pred that are exactly right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Want to do k-fold? It's like repeating the above. In pseudo code, it looks like:\n",
    "1. Break the X and y data into $k$ subsamples\n",
    "2. For each subsample, fit the model, predict OOS, score predictions, and save those\n",
    "Ok?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Fold in Python: The explicit way, and the wrapped way\n",
    "Watch me do the explicit way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can take quick notes here, but I'm not going to write this code slow enough to copy\n",
    "# the point here is to illustrate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try the wrapper below! We are going to see how to use that function to:\n",
    "\n",
    "1. try multiple models\n",
    "2. try different sets of X variables\n",
    "3. try different ways to specific folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try the function here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try here with diff scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the metrics it can compute out of the box are here: https://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "\n",
    "Notice that many of these were discussed in our last lecture!\n",
    "\n",
    "Warning/Note: the metric names on that link and what you put in the scoring dictionary don't seem to match up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.00071812, 0.00062728, 0.00076103, 0.00049591, 0.00042796]),\n",
       " 'score_time': array([0.00398207, 0.00260782, 0.00196385, 0.00183177, 0.00141215]),\n",
       " 'test_score': array([0.96666667, 0.96666667, 0.93333333, 0.93333333, 1.        ])}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate(model, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.00078011, 0.00046897, 0.00041771, 0.00096273, 0.00047112]),\n",
       " 'score_time': array([0.0061748 , 0.00281191, 0.00308228, 0.00249815, 0.002285  ]),\n",
       " 'test_accuracy': array([0.96666667, 0.96666667, 0.93333333, 0.93333333, 1.        ]),\n",
       " 'test_r2': array([0.95, 0.95, 0.9 , 0.9 , 1.  ]),\n",
       " 'test_precision_macro': array([0.96969697, 0.96969697, 0.94444444, 0.93333333, 1.        ])}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# answer here\n",
    "#Using 5 folds, what is the average (across the folds) out-of-sample (training) F1?\n",
    "cross_validate(model,X, y, scoring=['accuracy', 'r2', 'precision_macro'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9598319029897976"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate(model, X, y, scoring='f1_macro')['test_score'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the cross_validate parameters\n",
    "### The model parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.00057077, 0.00050998, 0.00051308, 0.00051403, 0.00056291]),\n",
       " 'score_time': array([0.00075221, 0.00089288, 0.00070381, 0.00068688, 0.00079107]),\n",
       " 'test_score': array([0.96658312, 1.        , 1.        , 0.96658312, 1.        ])}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# by changing the model parameter, you can adj the type of model and the models parameters\n",
    "cross_validate(SVC(gamma='auto'), X, y, scoring='f1_macro')\n",
    "cross_validate(SVC(C=5), X, y, scoring='f1_macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### question\n",
    "try to use a regression model, (you can't use f1 on this, so evaulate on r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32256072489000853"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# answer here\n",
    "cross_validate(LinearRegression(), X, y, scoring='r2')['test_score'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "linear_model submodule contains lots of useful alternate options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=10, class_weight=None, cv=None, dual=False,\n",
       "                     fit_intercept=True, intercept_scaling=1.0, l1_ratios=None,\n",
       "                     max_iter=100, multi_class='auto', n_jobs=None,\n",
       "                     penalty='l2', random_state=None, refit=True, scoring=None,\n",
       "                     solver='lbfgs', tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# for example:\n",
    "linear_model.Lasso\n",
    "linear_model.Ridge\n",
    "linear_model.LogisticRegression\n",
    "\n",
    "linear_model.LassoCV() # Returns a Lasso (L1 Regularization) linear model with picking the best model by cross validation\n",
    "linear_model.RidgeCV() # Returns a Ridge (L2 Regularization) linear model with picking the best model by cross validation\n",
    "linear_model.LogisticRegressionCV() # return best logit model by CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looping over models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set up models to try\n",
    "models = []\n",
    "models.append(('svc_1', SVC(gamma='auto') ))\n",
    "models.append(('svc_2', SVC(C=5) ))\n",
    "models.append(('neighbor',  KNeighborsClassifier(n_neighbors=1)))\n",
    "models[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svc_1     : 0.980 (0.016)\n",
      "svc_2     : 0.987 (0.016)\n",
      "neighbor  : 0.960 (0.025)\n"
     ]
    }
   ],
   "source": [
    "# loop and print\n",
    "for name, model in models:\n",
    "    scores = cross_validate(model, X, y, scoring='accuracy')\n",
    "    print('%s: %.3f (%.3f)' % (name.ljust(10), \n",
    "                                   scores['test_score'].mean(), \n",
    "                                   scores['test_score'].std()\n",
    "                                   )\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gridsearchCV\n",
    "randomizesearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The X parameter\n",
    "You can loop over Xs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-14-03903a534cc6>, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-14-03903a534cc6>\"\u001b[0;36m, line \u001b[0;32m9\u001b[0m\n\u001b[0;31m    right here!\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# define a smaller X and a bigger X\n",
    "X_small = X[:,:2] # just first two columns\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly = PolynomialFeatures(degree=3, include_bias=False)\n",
    "X3 = poly.fit_transform(X)\n",
    "\n",
    "# set up Xs to try\n",
    "right here!\n",
    "\n",
    "# loop and print\n",
    "right here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xs and Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CV parameter and folds\n",
    "Just watch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Links, resoruces, and next week\n",
    "Only two resources needed\n",
    "\n",
    "1. sklearn docs are GREAT https://scikit-learn.org/stable/user_guide.html\n",
    "2. Python Data Science Handbook (note some module calls are obsolete, so you might need to update code) https://jakevdp.github.io/PythonDataScienceHandbook/index.html\n",
    "\n",
    "Next week:\n",
    "\n",
    "1. preprocessing\n",
    "2. data transformations\n",
    "3. feasture selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
